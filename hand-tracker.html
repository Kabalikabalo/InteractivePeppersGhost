<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Blue Wireframe Hand (MediaPipe)</title>
<style>
  html, body { height: 100%; margin: 0; background: #000; overflow: hidden; }
  /* Canvas fills the screen; we draw the wireframe on it */
  #canvas { display:block; width:100vw; height:100vh; }
  /* Video is hidden; it just feeds frames to MediaPipe */
  #video { display:none; }
  .hint {
    position: fixed; left: 12px; bottom: 12px;
    color:#39a8ff; font: 12px/1.3 system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
    opacity:.7; user-select:none; pointer-events:none;
  }
</style>
</head>
<body>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div class="hint">Back camera • Blue wireframe • MediaPipe Hands</div>

  <!-- MediaPipe libraries -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <script>
    (async () => {
      const video  = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx    = canvas.getContext('2d', { alpha: false }); // opaque for performance

      // Prefer the back camera; gracefully fall back if needed.
      async function getBackCameraStream() {
        const attempts = [
          { video: { facingMode: { exact: 'environment' } }, audio: false },
          { video: { facingMode: 'environment' },           audio: false },
          { video: true,                                    audio: false }
        ];
        for (const constraints of attempts) {
          try {
            return await navigator.mediaDevices.getUserMedia(constraints);
          } catch (e) { /* try next */ }
        }
        throw new Error('No usable camera found.');
      }

      // Keep the canvas sized to the camera’s native resolution
      function resizeToVideo() {
        const w = video.videoWidth  || 1280;
        const h = video.videoHeight || 720;
        canvas.width  = w;
        canvas.height = h;
      }
      window.addEventListener('resize', resizeToVideo);

      // ---- MediaPipe Hands setup ----
      const hands = new Hands({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });
      hands.setOptions({
        maxNumHands: 2,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      hands.onResults((results) => {
        // Black background
        ctx.save();
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle = '#000';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // Blue wireframe
        if (results.multiHandLandmarks) {
          ctx.lineCap  = 'round';
          ctx.lineJoin = 'round';
          for (const landmarks of results.multiHandLandmarks) {
            // Lines between joints
            drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: '#1e90ff', lineWidth: 3 });
            // Joint points
            drawLandmarks(ctx,  landmarks,                     { color: '#1e90ff', radius: 2 });
          }
        }
        ctx.restore();
      });

      // ---- Start camera and processing loop ----
      try {
        const stream = await getBackCameraStream();
        video.srcObject = stream;
        await video.play();
      } catch (err) {
        alert('Camera error: ' + err.message + '\nTip: Use a device with a back camera and open this page via HTTPS.');
        return;
      }

      if (video.readyState >= 2) resizeToVideo();
      else video.addEventListener('loadedmetadata', resizeToVideo);

      async function tick() {
        if (video.readyState >= 2) {
          await hands.send({ image: video });
        }
        requestAnimationFrame(tick);
      }
      tick();
    })();
  </script>
</body>
</html>
